{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import shap\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from collections import defaultdict\n",
    "from scipy import stats\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "from qtrees.helper import get_logger, init_db_args\n",
    "from qtrees.constants import NOWCAST_FEATURES, FORECAST_FEATURES, HYPER_PARAMETERS_NC, HYPER_PARAMETERS_FC\n",
    "from qtrees.data_processor import DataLoader, PreprocessorForecast, PreprocessorNowcast\n",
    "sys.path.insert(0, os.path.abspath('../../qtrees-ai-data-private/'))\n",
    "from qtreesprivate.plots_util import apply_qtrees_style\n",
    "\n",
    "style.use(\"../../qtrees-ai-data-private/data/baumblick.mplstyle\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "DEPTH_MAP = {1: \"30 cm\", 2: \"60 cm\", 3: \"90 cm\"}\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_test_weeks(weeks, n_train_weeks=5, n_test_weeks=4):\n",
    "    train_weeks, test_weeks = [], []\n",
    "\n",
    "    i = 0\n",
    "    while i + n_train_weeks  < len(weeks):\n",
    "        # Define the training period\n",
    "        train_start = weeks[i]\n",
    "        train_end = weeks[i + min(n_train_weeks, len(weeks) - i) - 1]\n",
    "\n",
    "        # Define the testing period\n",
    "        test_start = weeks[i + n_train_weeks]\n",
    "        if i + n_train_weeks + n_test_weeks < len(weeks):\n",
    "            test_end = weeks[i + n_train_weeks + n_test_weeks -1]\n",
    "        else:\n",
    "            test_end = weeks[-1]\n",
    "        \n",
    "        train_weeks.extend(range(train_start, train_end + 1))  \n",
    "        test_weeks.extend(range(test_start, test_end + 1)) \n",
    "\n",
    "        i = i + n_train_weeks + n_test_weeks \n",
    "\n",
    "    return train_weeks, test_weeks\n",
    "\n",
    "def create_train_test_split_across_sites(data, n_splits=4):\n",
    "    train_data_folds, test_data_folds = [], []\n",
    "\n",
    "    # Create a KFold object\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    site_ids = data.site_id.unique()\n",
    "\n",
    "    for train_index, test_index in kf.split(site_ids):\n",
    "        train_data = data[data.site_id.isin(site_ids[train_index])]\n",
    "        test_data = data[data.site_id.isin(site_ids[test_index])]\n",
    "\n",
    "        # calculate the feature across only the train data and use it also for testing\n",
    "        temp = train_data.groupby([\"timestamp\",\"type_id\"])[\"value\"].mean().shift(1).rename(\"mean_yesterday\")\n",
    "        train_data = train_data.merge(temp, left_on=[\"timestamp\", \"type_id\"], right_index=True)\n",
    "        test_data = test_data.merge(temp, left_on=[\"timestamp\", \"type_id\"], right_index=True)\n",
    "\n",
    "        train_data_folds.append(train_data.dropna())\n",
    "        test_data_folds.append(test_data.dropna())\n",
    "\n",
    "    return list(zip(train_data_folds, test_data_folds))\n",
    "\n",
    "\n",
    "def log_experiment_results(fold_results, experiment_id=\"experiment1\", model=\"RandomForestRegressor\", features=[], hyper_parameters={}, csv_file=\"experiments.csv\"):\n",
    "    df = pd.DataFrame([{\"experiment_id\": experiment_id, \n",
    "                        \"Mean 30cm\": json.dumps({key: np.round(np.mean([d[key] for d in fold_results[\"Folds 30cm\"]]),2) for key in fold_results[\"Folds 30cm\"][0]}),\n",
    "                        \"Mean 60cm\": json.dumps({key: np.round(np.mean([d[key] for d in fold_results[\"Folds 60cm\"]]),2) for key in fold_results[\"Folds 60cm\"][0]}),\n",
    "                        \"Mean 90cm\": json.dumps({key: np.round(np.mean([d[key] for d in fold_results[\"Folds 90cm\"]]),2) for key in fold_results[\"Folds 90cm\"][0]}),\n",
    "                        \"Folds 30cm\": json.dumps(fold_results[\"Folds 30cm\"]), \n",
    "                        \"Folds 60cm\": json.dumps(fold_results[\"Folds 60cm\"]), \n",
    "                        \"Folds 90cm\": json.dumps(fold_results[\"Folds 90cm\"]), \n",
    "                        \"model\": model, \"features\": json.dumps(features), \n",
    "                        \"hyper_parameters\": json.dumps(hyper_parameters)}])\n",
    "\n",
    "    # Check if the file already exists; if not, write the header\n",
    "    write_header = not pd.io.common.file_exists(csv_file)\n",
    "\n",
    "    with open(csv_file, 'a', newline='') as file:\n",
    "        df.to_csv(file, mode='a', index=False, header=write_header)\n",
    "\n",
    "\n",
    "def read_experiment_log(csv_file):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    data['hyper_parameters'] = data['hyper_parameters'].apply(json.loads)\n",
    "    data['features'] = data['features'].apply(json.loads)\n",
    "    return data\n",
    "\n",
    "def predict_depth(model, test_data, type_id = 1, features=[]):\n",
    "    X_test, y_test = test_data.loc[test_data.type_id==type_id, features], test_data.loc[test_data.type_id==type_id,[\"value\"]]\n",
    "    \n",
    "    y_hat =  model.predict(X_test) # y_hat = np.expm1(model.predict(X_test))\n",
    "    rmse = mean_squared_error(y_test, y_hat, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_hat)\n",
    "\n",
    "    y_test.rename(columns={\"value\": \"y_test\"})\n",
    "    y_test[\"y_hat\"] = y_hat\n",
    "    y_test[\"tree_id\"] = test_data.loc[test_data.type_id==type_id, \"tree_id\"]\n",
    "    y_test[\"timestamp\"] = test_data.loc[test_data.type_id==type_id, \"timestamp\"]\n",
    "    y_test[\"benchmark\"] = test_data.loc[test_data.type_id==type_id, \"mean_yesterday\"]\n",
    "\n",
    "    #print(f\"Random Forest: Tiefe {DEPTH_MAP[type_id]}: RMSE {rmse:.2f}, MAE {mae:.2f}\")\n",
    "    return {\"rmse\": round(rmse, 2), \"mae\": round(mae, 2)}, y_test\n",
    "\n",
    "\n",
    "def predict_benchmark(test_data, type_id = 1, features=[]):\n",
    "    _, y_test = test_data.loc[test_data.type_id==type_id, features], test_data.loc[test_data.type_id==type_id, \"value\"]\n",
    "    y_hat_benchmark = test_data.loc[test_data.type_id==type_id, \"mean_yesterday\"]\n",
    "    rmse = mean_squared_error(y_test, y_hat_benchmark, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_hat_benchmark)\n",
    "    return {\"rmse\": round(rmse, 2), \"mae\": round(mae, 2)}, y_hat_benchmark\n",
    "\n",
    "def evaluate_benchmark_on_folds(folds, log_experiment=True):\n",
    "    fold_results = defaultdict(list)\n",
    "    for fold in folds:\n",
    "        fold_results[\"Folds 30cm\"].append(predict_benchmark(fold[1], type_id=1)[0])\n",
    "        fold_results[\"Folds 60cm\"].append(predict_benchmark(fold[1], type_id=2)[0])\n",
    "        fold_results[\"Folds 90cm\"].append(predict_benchmark(fold[1], type_id=3)[0])\n",
    "    if log_experiment:\n",
    "        log_experiment_results(fold_results, experiment_id=\"Benchmark\", model=\"Benchmark\", features=[], hyper_parameters={})\n",
    "        \n",
    "    return fold_results\n",
    "\n",
    "def init_result_folder(name):\n",
    "    folder_path = os.path.join(\".\", name)  # Use \".\" to create the folder in the current directory\n",
    "\n",
    "    if os.path.exists(folder_path):\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                os.rmdir(file_path)\n",
    "    else:\n",
    "        os.makedirs(folder_path)\n",
    "\n",
    "    return folder_path\n",
    "\n",
    "def plot_predictions(predictions, path):\n",
    "    y_min, y_max = 0.0, predictions.value.max()\n",
    "    min_date, max_date = predictions.timestamp.min(), predictions.timestamp.max()\n",
    "    idx = pd.DatetimeIndex(pd.date_range(start=min_date, end=max_date, freq='D'))\n",
    "\n",
    "    for tree in predictions.tree_id.unique():\n",
    "        plot_data = predictions[(predictions.tree_id==tree) & (predictions.type_id==1)].set_index(\"timestamp\").sort_index()\n",
    "        \n",
    "        if len(plot_data) > 0:\n",
    "            mae_forecast = mean_absolute_error(plot_data[\"value\"], plot_data[\"y_hat\"])\n",
    "            mae_benchmark = mean_absolute_error(plot_data[\"value\"], plot_data[\"benchmark\"])\n",
    "            plot_data = plot_data.reindex(idx)\n",
    "            \n",
    "            fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "            plot_data.value.plot(ax=ax[0], label=\"Sensorwert\")\n",
    "            plot_data.y_hat.plot(ax=ax[0], label=\"Vorhersage\")\n",
    "            plot_data.benchmark.plot(ax=ax[0], label=\"Benchmark\")\n",
    "            ax[0].set_ylim((y_min, y_max))\n",
    "            ax[0].set_xlim((\"2022-04\", \"2022-09\"))\n",
    "            ax[0].xaxis.grid(False)\n",
    "\n",
    "            plot_data.value.plot(ax=ax[1], label=\"Sensorwert\")\n",
    "            plot_data.y_hat.plot(ax=ax[1], label=\"Vorhersage\")\n",
    "            plot_data.benchmark.plot(ax=ax[1], label=\"Benchmark\")\n",
    "            ax[1].set_ylim((y_min, y_max))\n",
    "            ax[1].set_xlim((\"2023-04\", \"2023-09\"))\n",
    "            #ax[1].legend()\n",
    "            ax[1].xaxis.grid(False)\n",
    "\n",
    "            apply_qtrees_style(fig,f\"Tree {tree}, Tiefe 30cm\",f\"Vorhersage MAE: {mae_forecast:.2f}, Benchmark MAE: {mae_benchmark:.2f}\")\n",
    "            ax[0].get_legend().set_visible(False)\n",
    "        \n",
    "        plt.savefig(os.path.join(path, f\"forecast_{tree}.png\"), bbox_inches=\"tight\")\n",
    "\n",
    "def evaluate_folds(folds, name, model, hyper_parameters, features, explain_model=False, log_experiment=True):\n",
    "    fold_results = defaultdict(list)\n",
    "    predictions = []\n",
    "    path = init_result_folder(name)\n",
    "    \n",
    "    for idx, fold in enumerate(folds):\n",
    "        prediction_list = []\n",
    "        X_train, y_train = fold[0][features], fold[0][\"value\"]\n",
    "        for depth in [1, 2, 3]:\n",
    "            model.fit(X_train, y_train)\n",
    "            results, pred = predict_depth(model, fold[1], type_id=depth, features=features)\n",
    "            fold_results[f\"Folds {30*depth}cm\"].append(results)\n",
    "            pred[\"type_id\"] = depth\n",
    "            prediction_list.append(pred)\n",
    "\n",
    "        fold_predictions = pd.concat(prediction_list, ignore_index=True)\n",
    "        fold_predictions[\"fold\"] = idx\n",
    "        predictions.append(fold_predictions)\n",
    "    \n",
    "        if explain_model and idx == 0:\n",
    "            feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': model.feature_importances_})\n",
    "            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "            feature_importance_df.to_csv(os.path.join(path, f\"feature_importance_fold_{idx}.csv\"))\n",
    "            feature_importance_df.set_index(\"Feature\").plot(kind=\"barh\")\n",
    "            plt.savefig(os.path.join(path, f\"feature_importance_fold_{idx}.png\"), bbox_inches=\"tight\")\n",
    "            \n",
    "            mask = np.random.choice(range(len(X_train)),size=200, replace=False)\n",
    "            explainer = shap.Explainer(model, X_train.iloc[mask,])\n",
    "            shap_values = explainer(X_train)\n",
    "            shap.plots.bar(shap_values)\n",
    "            plt.savefig(os.path.join(path, f\"shap_values_{idx}.png\"), bbox_inches=\"tight\")\n",
    "\n",
    "            shap.plots.violin(shap_values)\n",
    "            plt.savefig(os.path.join(path, f\"shap_values_violin_{idx}.png\"), bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "    if log_experiment:\n",
    "        log_experiment_results(fold_results, experiment_id=name, model=model.__class__.__name__, features=features, hyper_parameters=hyper_parameters)\n",
    "        \n",
    "    total_predictions = pd.concat(predictions, ignore_index=True)\n",
    "    total_predictions.to_csv(os.path.join(path, f\"predictions_fold_{idx}.csv\"))\n",
    "\n",
    "    #plot_predictions(total_predictions, path)\n",
    "\n",
    "    return fold_results, total_predictions\n",
    "\n",
    "def results_dict_to_df(res_dict, name):\n",
    "    x = pd.DataFrame({\"rmse\":0,\"mae\":0, \"name\":name}, index=[\"Folds 30cm\", \"Folds 60cm\", \"Folds 90cm\"])\n",
    "    for ind in x.index:\n",
    "        for metric in [\"rmse\",\"mae\"]:\n",
    "            temp = 0\n",
    "            for i in range(len(res_dict)):\n",
    "                temp += res_dict[ind][i][metric]\n",
    "            x.loc[ind,metric] = temp/len(res_dict)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed data (DEV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_qtrees, postgres_passwd = \"\",\"\"#Add user and password\n",
    "engine = create_engine(\n",
    "    f\"postgresql://qtrees_user:{postgres_passwd}@{db_qtrees}:5432/qtrees\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval run nowcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = DataLoader(engine) #Downloads data\n",
    "train_data_raw = enc.download_training_data(forecast=False)\n",
    "prep_nowcast = PreprocessorNowcast()\n",
    "prep_nowcast.fit(train_data_raw)\n",
    "train_data_nowcast = prep_nowcast.transform_train(train_data_raw)\n",
    "train_data_nowcast.rename(columns={\"target\":\"value\"},inplace=True)\n",
    "train_data_nowcast.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Things to change\n",
    "#for md in [2, 3, 4, 5, 8, 13]:\n",
    "\n",
    "#hyper_parameters=dict(n_estimators=1000, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "#model = XGBRegressor(**hyper_parameters)\n",
    "data_eval = train_data_nowcast.drop(columns=\"mean_yesterday\")\n",
    "folds = create_train_test_split_across_sites(data_eval, n_splits=4)\n",
    "\n",
    "#This is already optimised. I did the grid search\n",
    "hyper_parameter_grid = [\n",
    "    dict(n_estimators=200, learning_rate=0.01, max_depth=5, max_features='sqrt'),\n",
    "    dict(fit_intercept=True),\n",
    "    dict(max_features=\"sqrt\", criterion=\"squared_error\", n_estimators=300, max_depth=5, bootstrap=True)\n",
    "]\n",
    "models = [\n",
    "    GradientBoostingRegressor,\n",
    "    LinearRegression,\n",
    "    RandomForestRegressor\n",
    "]\n",
    "res_list = []\n",
    "pred_list = []\n",
    "for hyper_parameters, model in zip(hyper_parameter_grid,models):\n",
    "    results, predictions = evaluate_folds(folds, model.__name__, model(**hyper_parameters), hyper_parameters=hyper_parameters, features=NOWCAST_FEATURES, explain_model=False)\n",
    "    res_list.append(results_dict_to_df(results, model.__name__))\n",
    "    predictions[\"model\"] = model.__name__\n",
    "    pred_list.append(predictions)\n",
    "#results = evaluate_benchmark_on_folds(folds, log_experiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pred_list[0].copy()\n",
    "temp[\"model\"] = \"benchmark\"\n",
    "temp = temp[[\"value\",\"benchmark\",\"tree_id\",\"type_id\",\"model\"]]\n",
    "temp = temp.rename(columns={\"benchmark\":\"y_hat\"})\n",
    "\n",
    "pred_results = pd.concat([pd.concat(pred_list)[[\"value\",\"y_hat\",\"tree_id\",\"type_id\",\"model\"]],temp])\n",
    "pred_results[\"error\"] = abs(pred_results[\"y_hat\"] - pred_results[\"value\"])\n",
    "\n",
    "pred_results[\"type_id\"] = pd.Categorical(pred_results[\"type_id\"]).rename_categories(list(DEPTH_MAP.values()))\n",
    "pred_results = pred_results.rename(columns={\"type_id\":\"Sensortiefe\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax = sns.boxplot(data =pred_results, x=\"Sensortiefe\", y=\"error\", hue=\"model\")\n",
    "sns.move_legend(ax, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "apply_qtrees_style(fig,\"Violinenplots der absoluten Fehler\",\"für drei optimierte Modelle und Benchmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Shap values no cross validation. Just train on the entire dataset and look at the results per depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type_id in [1]:\n",
    "    model = RandomForestRegressor(**HYPER_PARAMETERS_NC)\n",
    "    X_train = train_data_nowcast[train_data_nowcast.type_id == type_id][NOWCAST_FEATURES]\n",
    "    y_train = train_data_nowcast[train_data_nowcast.type_id == type_id][\"value\"]\n",
    "    na_mask = X_train.isna().sum(axis=1) == 0\n",
    "    X_train, y_train = X_train[na_mask], y_train[na_mask]\n",
    "    model.fit(X_train, y_train)\n",
    "    mask = np.random.choice(range(len(X_train)),size=200, replace=False)\n",
    "    explainer = shap.Explainer(model, X_train.iloc[mask,])\n",
    "    shap_values = explainer(X_train)\n",
    "    shap.plots.bar(shap_values)\n",
    "    shap.plots.violin(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_benchmark = evaluate_benchmark_on_folds(folds, log_experiment=True)\n",
    "res_benchmark = results_dict_to_df(result_benchmark,\"benchmark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_smartgrp = pd.concat(res_list + [res_benchmark]).set_index([\"name\"], append=True).reorder_levels([1,0])\n",
    "res_smartgrp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfiltered data (PROD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_qtrees, postgres_passwd = \"\",\"\"#Add user and password\n",
    "engine_prod = create_engine(\n",
    "    f\"postgresql://qtrees_user:{postgres_passwd}@{db_qtrees}:5432/qtrees\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_prod = DataLoader(engine_prod) #Downloads data\n",
    "train_data_raw_prod = enc_prod.download_training_data(forecast=False)\n",
    "prep_nowcast_prod = PreprocessorNowcast()\n",
    "prep_nowcast_prod.fit(train_data_raw_prod)\n",
    "train_data_prod = prep_nowcast_prod.transform_train(train_data_raw_prod)\n",
    "train_data_prod.rename(columns={\"target\":\"value\"},inplace=True)\n",
    "train_data_prod.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Things to change\n",
    "#for md in [2, 3, 4, 5, 8, 13]:\n",
    "#hyper_parameters=dict(n_estimators=1000, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "#model = XGBRegressor(**hyper_parameters)\n",
    "data_eval_prod = train_data_prod.drop(columns=\"mean_yesterday\")\n",
    "folds_prod = create_train_test_split_across_sites(data_eval_prod, n_splits=4)\n",
    "\n",
    "hyper_parameter_grid = [\n",
    "    dict(max_features=\"sqrt\",criterion=\"squared_error\", n_estimators=1000, max_depth=5, bootstrap=True),\n",
    "    dict(n_estimators=100, learning_rate=0.03, max_depth=3, max_features=\"sqrt\"),\n",
    "    dict(fit_intercept=True)\n",
    "]\n",
    "models = [\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    LinearRegression\n",
    "]\n",
    "\n",
    "res_list_prod = []\n",
    "for hyper_parameters, model in zip(hyper_parameter_grid,models):\n",
    "    results, predictions = evaluate_folds(folds_prod, \"Prod run no group: \" + model.__name__, model(**hyper_parameters), hyper_parameters=hyper_parameters, features=NOWCAST_FEATURES)\n",
    "    res_list_prod.append(results_dict_to_df(results, model.__name__))\n",
    "#results = evaluate_benchmark_on_folds(folds, log_experiment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_benchmark = results_dict_to_df(evaluate_benchmark_on_folds(folds_prod, log_experiment=True),\"benchmark\")\n",
    "res_prod_nogrp = pd.concat(res_list_prod + [result_benchmark]).set_index([\"name\"], append=True).reorder_levels([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_smartgrp / res_prod_nogrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_prod_nogrp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: Preprocessing works really well. We can decrease error by A LOT. Made sense to put so much energy into it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive grouping approach: Just average over the sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_grp = train_data_prod.groupby([\"site_id\",\"type_id\",\"timestamp\"]).mean(numeric_only=True).dropna().reset_index()\n",
    "train_grp[\"tree_id\"] = train_grp[\"site_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval_prod = train_grp.drop(columns=\"mean_yesterday\")\n",
    "folds_prod = create_train_test_split_across_sites(data_eval_prod, n_splits=4)\n",
    "\n",
    "hyper_parameter_grid = [\n",
    "    dict(max_features=\"sqrt\",criterion=\"squared_error\", n_estimators=300, max_depth=5, bootstrap=True),\n",
    "    dict(n_estimators=100, learning_rate=0.03, max_depth=3, max_features=\"sqrt\"),\n",
    "    dict(fit_intercept=True)\n",
    "]\n",
    "models = [\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    LinearRegression\n",
    "]\n",
    "\n",
    "res_list_prod = []\n",
    "for hyper_parameters, model in zip(hyper_parameter_grid,models):\n",
    "    results, predictions = evaluate_folds(folds_prod, \"Prod run naive group: \" + model.__name__, model(**hyper_parameters), hyper_parameters=hyper_parameters, features=NOWCAST_FEATURES)\n",
    "    res_list_prod.append(results_dict_to_df(results, model.__name__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_benchmark = results_dict_to_df(evaluate_benchmark_on_folds(folds_prod, log_experiment=True),\"benchmark\")\n",
    "res_prod_naivegrp = pd.concat(res_list_prod + [result_benchmark]).set_index([\"name\"], append=True).reorder_levels([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_prod_naivegrp.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive grouping does not really help at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the forecast method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weeks = [pd.Timestamp(x, tz=\"UTC\") for x in [\"2022-06-16\",\"2022-09-01\",\"2023-05-01\",\"2023-08-01\"]]\n",
    "drop_weeks = [pd.Timestamp(x, tz=\"UTC\") for x in [\"2022-06-09\",\"2022-08-25\",\"2023-04-24\",\"2023-07-24\"]]\n",
    "test_window = pd.concat([pd.date_range(x,periods=14, tz=\"UTC\").to_series() for x in test_weeks])\n",
    "drop_window = pd.concat([pd.date_range(x,periods=21, tz=\"UTC\").to_series() for x in drop_weeks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_fc = PreprocessorForecast()\n",
    "prep_fc.fit(train_data_raw)\n",
    "forecast_data_eval = prep_fc.transform_train(train_data_raw)\n",
    "test_forecast = forecast_data_eval[forecast_data_eval.index.get_level_values(1).isin(test_window)]\n",
    "train_forecast = forecast_data_eval[~forecast_data_eval.index.get_level_values(1).isin(drop_window)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_MVP = FORECAST_FEATURES + [\"shift_1\",\"shift_2\",\"shift_3\"]\n",
    "\n",
    "y_train_fc = train_forecast[\"target\"]\n",
    "X_train_fc = train_forecast.drop(columns=\"target\")\n",
    "mask = X_train_fc.isna().sum(axis=1) == 0\n",
    "y_train_fc = y_train_fc[mask]\n",
    "X_train_fc = X_train_fc[mask]\n",
    "model = RandomForestRegressor(**HYPER_PARAMETERS_FC)\n",
    "model.fit(X_train_fc[FEATURES_MVP],y_train_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_forecast = test_forecast.dropna()\n",
    "test_fc_noautoreg = test_forecast.drop(columns=[\"shift_1\",\"shift_2\",\"shift_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = pd.DataFrame(data = {'timestamp':test_forecast.index.get_level_values(1), \n",
    "                     'tree_id': test_forecast.index.get_level_values(0), \n",
    "                     'y_true': test_fc_noautoreg[\"target\"], \n",
    "                     \"y_pred\":0})\n",
    "pred_results.set_index(['timestamp', 'tree_id'], inplace=True)\n",
    "autoreg_features = test_forecast.reset_index(level=0).loc[test_weeks][[\"type_id\",\"tree_id\",\"shift_1\",\"shift_2\",\"shift_3\"]].reset_index()\n",
    "pred_results = None\n",
    "for h in range(14):\n",
    "    dates = [x + dt.timedelta(days=h) for x in test_weeks]\n",
    "    temp = test_fc_noautoreg.reset_index(level=0).loc[dates].set_index([\"tree_id\", \"type_id\"], append=True)\n",
    "    temp = temp.merge(autoreg_features, how=\"inner\", left_index=True, right_on = [\"timestamp\", \"tree_id\", \"type_id\"]).drop(columns=\"target\").set_index([\"tree_id\",\"timestamp\"])\n",
    "    ind = temp.reset_index().set_index([\"timestamp\", \"tree_id\", \"type_id\"]).index\n",
    "    res = model.predict(temp[model.feature_names_in_])\n",
    "    if pred_results is None:\n",
    "        pred_results = pd.DataFrame(data = {\"y_pred\":res},index=ind)\n",
    "        pred_results[\"window\"] = h+1\n",
    "    else:\n",
    "        temp = pd.DataFrame(data = {\"y_pred\":res},index=ind)\n",
    "        temp[\"window\"] = h+1\n",
    "        pred_results = pd.concat([pred_results, temp])\n",
    "    autoreg_features = autoreg_features.set_index(['timestamp','tree_id','type_id']).loc[ind].reset_index()\n",
    "    autoreg_features[\"shift_3\"] = autoreg_features[\"shift_2\"]\n",
    "    autoreg_features[\"shift_2\"] = autoreg_features[\"shift_1\"]\n",
    "    autoreg_features[\"shift_1\"] = res\n",
    "    autoreg_features[\"timestamp\"] = autoreg_features[\"timestamp\"] + dt.timedelta(days=1)\n",
    "pred_results = pred_results.merge(test_fc_noautoreg.reset_index().set_index([\"timestamp\",\"tree_id\",\"type_id\"]).loc[pred_results.index,\"target\"], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE: ', mean_absolute_error(pred_results[\"target\"], pred_results[\"y_pred\"]), '    RMSE: ', mean_squared_error(pred_results[\"target\"], pred_results[\"y_pred\"], squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dict(importance=model.feature_importances_),index=model.feature_names_in_).sort_values(\"importance\").plot.barh(legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.choice([False,True],size=X_train_fc.shape[0], replace=True, p=[0.94,0.06])\n",
    "explainer = shap.Explainer(model, X_train_fc.loc[mask, FEATURES_MVP])\n",
    "shap_values = explainer(X_train_fc.loc[mask, FEATURES_MVP])\n",
    "shap.plots.bar(shap_values)\n",
    "shap.plots.violin(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_res = np.abs(shap_values.values)\n",
    "pd.DataFrame(dict(shap_value=shap_res.sum(axis=0)/shap_res.sum()), index=shap_values.feature_names).sort_values(\"shap_value\", ascending=False)[3:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(8,4))\n",
    "ax.plot(pred_results.reset_index().groupby(\"window\").apply(lambda x: np.sqrt(mean_squared_error(x['target'], x['y_pred']))))\n",
    "ax.plot(pred_results.reset_index().groupby(\"window\").apply(lambda x: mean_absolute_error(x['target'], x['y_pred'])))\n",
    "apply_qtrees_style(fig,\"Fehler der Vorhersage nach Prognosehorizont\", \"RMSE (grün) und MAE (orange)\")\n",
    "ax.set_xlabel(\"Prognosehorizont\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results[\"error\"] = pred_results[\"target\"] - pred_results[\"y_pred\"]\n",
    "sigma = np.std(pred_results[\"error\"])\n",
    "mu = np.mean(pred_results[\"error\"])\n",
    "x = np.linspace(-100, 100, 201)\n",
    "\n",
    "pred_results[\"error\"].hist(bins=20, density=True)\n",
    "plt.plot(x, stats.norm.pdf(x, mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [\"00008100:0024c2fe\", \"00008100:002927d6\"]\n",
    "\n",
    "fig, axs = plt.subplots(nrows = len(trees),figsize = (10,5))\n",
    "for i, tree in enumerate(trees):\n",
    "    plot_df = pred_results.loc[(\"2023-08\",tree,1),(\"y_pred\",\"target\")]\n",
    "    before = forecast_data_eval[forecast_data_eval.type_id==1].loc[tree].sort_index().loc[drop_weeks[3]:test_weeks[3]-dt.timedelta(days=1),\"target\"].rename(\"old\")\n",
    "    if before.shape[0] > 0:\n",
    "        plot_df = plot_df.merge(before, how=\"outer\",left_index=True,right_index=True)\n",
    "        plot_df.loc[\"2023-07-31\",[\"y_pred\",\"target\"]] = plot_df.loc[\"2023-07-31\",\"old\"]\n",
    "    axs[i].plot(plot_df.sort_index())\n",
    "    axs[i].axvline(dt.date(2023,8,1),color=\"grey\")\n",
    "    axs[i].set_xticks([\"2023-07-24\", \"2023-07-31\",\"2023-08-07\", \"2023-08-14\"],labels=[\"24.07.23\", \"31.07.23\",\"07.08.23\", \"14.08.23\"])\n",
    "fig.legend([\"Vorhersage\",\"Zielwert\",\"Vor Evaluation\"])\n",
    "apply_qtrees_style(fig,\"14-Tage-Vorhersage anhand zweier beispielhafter Bäume\",\"für den Evaluationszeitraum Anfang August 2023 auf 30cm Tiefe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree_id in pred_results.index.get_level_values(1).unique():\n",
    "    plot_df = pred_results.loc[(\"2023-08\",tree_id,1),(\"y_pred\",\"target\")]\n",
    "    if plot_df.shape[0] > 0:\n",
    "        plot_df = plot_df.assign(tree_id=tree_id)\n",
    "        before = forecast_data_eval[forecast_data_eval.type_id==1].loc[tree_id].sort_index().loc[drop_weeks[3]:test_weeks[3]-dt.timedelta(days=1),\"target\"].rename(\"old\")\n",
    "        if before.shape[0] > 0:\n",
    "            plot_df = plot_df.merge(before, how=\"outer\",left_index=True,right_index=True)\n",
    "            plot_df.loc[\"2023-07-31\",[\"y_pred\",\"target\"]] = plot_df.loc[\"2023-07-31\",\"old\"]\n",
    "        plot_df.sort_index().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting a full season with starting values\n",
    "\n",
    "Trying to understand whether we actually need sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_fullseason_data = forecast_data_eval.sort_index(level=1).reset_index(level=0).loc[\"2023\"].set_index(\"tree_id\",append=True).reorder_levels([1,0])\n",
    "autoreg_features = forecast_fullseason_data.index.get_level_values(0).unique()\n",
    "autoreg_features = autoreg_features.to_frame().merge(pd.DataFrame({\"timestamp\":pd.Timestamp(\"2023-04-01\",tz=\"UTC\"),\"type_id\":[1,2,3]}), how=\"cross\")\n",
    "autoreg_features = autoreg_features.assign(shift_1=20, shift_2=20, shift_3=20)\n",
    "target = forecast_fullseason_data.set_index(\"type_id\",append=True)[\"target\"]\n",
    "forecast_fullseason_data = forecast_fullseason_data.drop(columns=[\"shift_1\",\"shift_2\",\"shift_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_season_forecast = forecast_data_eval.sort_index(level=1).reset_index(level=0).loc[:\"01-01-2023\"].set_index(\"tree_id\",append=True).reorder_levels([1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_MVP = FORECAST_FEATURES + [\"shift_1\",\"shift_2\",\"shift_3\"]\n",
    "\n",
    "y_train_fc = train_season_forecast[\"target\"]\n",
    "X_train_fc = train_season_forecast.drop(columns=\"target\")\n",
    "X_train_fc = X_train_fc[FEATURES_MVP + [\"type_id\"]]\n",
    "mask = X_train_fc.isna().sum(axis=1) == 0\n",
    "y_train_fc = y_train_fc[mask]\n",
    "X_train_fc = X_train_fc[mask]\n",
    "model = RandomForestRegressor(**HYPER_PARAMETERS_FC)\n",
    "model.fit(X_train_fc,y_train_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = None\n",
    "date = dt.date(2023,4,1)\n",
    "window = 0\n",
    "while date < dt.date(2023, 10, 1):\n",
    "    temp = forecast_fullseason_data.reset_index(level=0).sort_index().loc[date.strftime(\"%Y-%m-%d\")].set_index([\"tree_id\", \"type_id\"], append=True)\n",
    "    temp = temp.merge(autoreg_features, how=\"left\", left_index=True, right_on = [\"timestamp\", \"tree_id\", \"type_id\"]).drop(columns=\"target\").set_index([\"tree_id\",\"timestamp\"])\n",
    "    temp.loc[:,[\"shift_1\",\"shift_2\",\"shift_3\"]] = temp.loc[:,[\"shift_1\",\"shift_2\",\"shift_3\"]].fillna(20)\n",
    "    temp = temp[model.feature_names_in_].dropna()\n",
    "    ind = temp.reset_index().set_index([\"timestamp\", \"tree_id\", \"type_id\"]).index\n",
    "    res = model.predict(temp)\n",
    "    if pred_results is None:\n",
    "        pred_results = pd.DataFrame(data = {\"y_pred\": res},index=ind)\n",
    "    else:\n",
    "        res_step = pd.DataFrame(data = {\"y_pred\": res},index=ind)\n",
    "        pred_results = pd.concat([pred_results, res_step])\n",
    "    autoreg_features = temp.set_index(\"type_id\",append=True).loc[:,[\"shift_1\",\"shift_2\",\"shift_3\"]].reset_index()\n",
    "    autoreg_features[\"shift_3\"] = autoreg_features[\"shift_2\"]\n",
    "    autoreg_features[\"shift_2\"] = autoreg_features[\"shift_1\"]\n",
    "    autoreg_features[\"shift_1\"] = res\n",
    "    autoreg_features[\"timestamp\"] = autoreg_features[\"timestamp\"] + dt.timedelta(days=1)\n",
    "    date = date + dt.timedelta(days=1)\n",
    "    window += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_season_predictions = pred_results.reorder_levels([1,0,2]).merge(target, how=\"left\", left_index=True, right_index=True)\n",
    "full_season_predictions[\"error\"] = full_season_predictions[\"target\"] - full_season_predictions[\"y_pred\"] \n",
    "print(\"MAE: \" + str(full_season_predictions[\"error\"].abs().mean()))\n",
    "print(\"RMSE: \" + str(full_season_predictions[\"error\"].std()))\n",
    "print(\"Bias: \" + str(full_season_predictions[\"error\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tree_id in full_season_predictions.index.get_level_values(0).unique():\n",
    "    temp = full_season_predictions.loc[tree_id,:,1].loc[:,[\"y_pred\",\"target\"]]\n",
    "    if temp.shape[0] > 0:\n",
    "        temp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.random.choice([False,True],size=X_train_fc.shape[0], replace=True, p=[0.96,0.04])\n",
    "explainer = shap.Explainer(model, X_train_fc.loc[mask, :])\n",
    "shap_values = explainer(X_train_fc.loc[mask, :])\n",
    "shap.plots.bar(shap_values)\n",
    "shap.plots.violin(shap_values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
