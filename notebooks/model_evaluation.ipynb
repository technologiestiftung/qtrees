{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple train test split and calc errors\n",
    "# model 1: current random forest\n",
    "# model 2: all features\n",
    "# model 3: something in the middle\n",
    "# create split across trees (with groups)\n",
    "# create split across time\n",
    "# create split across trees and time\n",
    "# check leakage across time and groups\n",
    "# benchmarks?\n",
    "# with sensor and without as feature\n",
    "# differen horizon\n",
    "# Questions:\n",
    "# Ein Model je Tiefe oder Tiefe als Variable?\n",
    "# Ein \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../../../qtrees-ai-data-private\")\n",
    "\n",
    "from qtreesprivate.preprocessed_data import Preprocessor\n",
    "\n",
    "from qtrees.helper import get_logger, init_db_args\n",
    "from qtrees.constants import NOWCAST_FEATURES, FORECAST_FEATURES\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "DEPTH_MAP = {1: \"30 cm\", 2: \"60 cm\", 3: \"90 cm\"}\n",
    "\n",
    "CAT_FEATURES = [\"baumscheibe_surface\", \"gattung\", \"month\", \"baumscheibe_cat\", \"standalter_cat\"]\n",
    "NUM_FEATURES = [\"water_sga\",\"water_gdk\", \"shading_index\", \"wind_max_ms\", \"rainfall_mm\", \"temp_avg_c\", \"ghi_sum_whm2\", \"gestern\", \"upm\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev\n",
    "#user = \"qtrees_user\"\n",
    "#postgres_passwd = \"\"\n",
    "#db_qtrees = \"qtreesdev-iac-rds.ct3edyn2bzjb.eu-central-1.rds.amazonaws.com\"\n",
    "#\n",
    "#engine = create_engine(\n",
    "#    f\"postgresql://{user}:{postgres_passwd}@{db_qtrees}:5432/qtrees\"\n",
    "#)\n",
    "#\n",
    "#pp = Preprocessor(engine)\n",
    "#pp.processing_pipeline()\n",
    "#data = pp.data\n",
    "#data.info()\n",
    "#data.to_pickle(\"data.p\")\n",
    "\n",
    "#tree_devices = pd.read_sql(con= engine, sql=\"SELECT * FROM private.tree_devices\")\n",
    "#tree_devices.to_pickle(\"tree_devices.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data.p\")\n",
    "data = data.drop(\"gestern\", axis=1)\n",
    "temp = data.groupby([\"timestamp\", \"type_id\"])[\"value\"].mean().shift(1).rename(\"gestern\")\n",
    "data = data.merge(temp, left_on=[\"timestamp\", \"type_id\"], right_index=True)\n",
    "\n",
    "tree_devices = pd.read_pickle(\"tree_devices.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_POC = [\"type_id\", \"temp_avg_c\", \"rainfall_mm\", \"water_sga\", \"water_gdk\", \"month\", \"gestern\"] #, \"standalter_cat\", \"shading_index\", \n",
    "FEATURES_MVP = [\"type_id\", \"shading_index\", \"standalter_cat\", \"temp_avg_c\", \"rainfall_mm\", \"water_sga\", \"water_gdk\", \"month\", \"gestern\", \"baumscheibe_surface\", \"gattung\", \"baumscheibe_cat\", \"wind_max_ms\", \"ghi_sum_whm2\", \"upm\"]\n",
    "FEATURE_NAIVE = [\"gestern\"]\n",
    "\n",
    "clean_idx = data.loc[data.timestamp < \"2023-09\", FEATURES_MVP].dropna().index\n",
    "clean_data = data.loc[clean_idx]\n",
    "clean_data = clean_data.merge(tree_devices[[\"tree_id\", \"site_id\"]], how=\"left\", left_on=\"tree_id\", right_on=\"tree_id\")\n",
    "\n",
    "#create categories\n",
    "CAT_FEATURES = [\"baumscheibe_surface\", \"gattung\", \"month\", \"baumscheibe_cat\", \"standalter_cat\"]\n",
    "for c in [x for x in FEATURES_MVP if x in CAT_FEATURES]:\n",
    "    clean_data.loc[:,c] = clean_data.loc[:,c].factorize()[0]\n",
    "\n",
    "for c in [x for x in FEATURES_MVP if x in NUM_FEATURES]:\n",
    "    clean_data.loc[:,c] = (clean_data.loc[:,c]-clean_data.loc[:,c].mean())/clean_data.loc[:,c].std()\n",
    "\n",
    "clean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.groupby(pd.Grouper(key='timestamp', freq='M')).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "site_ids = clean_data.site_id.unique()\n",
    "test_site_ids = np.random.choice(site_ids, int(.25*len(site_ids)), replace=False) \n",
    "#test_site_ids = [316,  68, 235,  55,  18,  62] #,  74,  65, 321,  69,  95]\n",
    "test_site_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_test_weeks(weeks, n_train_weeks=5, n_test_weeks=4):\n",
    "    train_weeks, test_weeks = [], []\n",
    "\n",
    "    i = 0\n",
    "    while i + n_train_weeks  < len(weeks):\n",
    "        # Define the training period\n",
    "        train_start = weeks[i]\n",
    "        train_end = weeks[i + min(n_train_weeks, len(weeks) - i) - 1]\n",
    "\n",
    "        # Define the testing period\n",
    "        test_start = weeks[i + n_train_weeks]\n",
    "        if i + n_train_weeks + n_test_weeks < len(weeks):\n",
    "            test_end = weeks[i + n_train_weeks + n_test_weeks -1]\n",
    "        else:\n",
    "            test_end = weeks[-1]\n",
    "        \n",
    "        train_weeks.extend(range(train_start, train_end + 1))  \n",
    "        test_weeks.extend(range(test_start, test_end + 1)) \n",
    "\n",
    "        i = i + n_train_weeks + n_test_weeks \n",
    "\n",
    "    return train_weeks, test_weeks\n",
    "    \n",
    "weeks = sorted(clean_data.timestamp.dt.isocalendar().week.unique())\n",
    "train_weeks, test_weeks = pick_test_weeks(weeks)\n",
    "train_weeks, test_weeks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = ~clean_data.site_id.isin(test_site_ids)\n",
    "train_data = clean_data[train_mask]\n",
    "\n",
    "#test_mask = (clean_data.site_id.isin(test_site_ids)) & (clean_data.timestamp.dt.isocalendar().week.isin(test_weeks))\n",
    "test_mask = (clean_data.site_id.isin(test_site_ids))\n",
    "test_data = clean_data[test_mask]\n",
    "\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data[FEATURES_MVP], train_data[\"value\"]\n",
    "\n",
    "d = 4\n",
    "rf = RandomForestRegressor(max_features=\"sqrt\", n_estimators=1000, max_depth=d, bootstrap=True)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Testen je Tiefe\n",
    "def predict_depth(model, test_data, depth = 1):\n",
    "    X_test, y_test = test_data.loc[test_data.type_id==depth, FEATURES_MVP], test_data.loc[test_data.type_id==depth, \"value\"]\n",
    "    \n",
    "    y_hat = model.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_hat, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_hat)\n",
    "    print(X_test.columns)\n",
    "    print(model.feature_importances_)\n",
    "    print(f\"Random Forest: Tiefe {DEPTH_MAP[depth]}: RMSE {rmse:.2f}, MAE {mae:.2f}\")\n",
    "\n",
    "\n",
    "    y_hat_benchmark = test_data.loc[test_data.type_id==depth, \"gestern\"]\n",
    "    rmse = mean_squared_error(y_test, y_hat_benchmark, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_hat_benchmark)\n",
    "    print(f\"Benchmark: Tiefe {DEPTH_MAP[depth]}: RMSE {rmse:.2f}, MAE {mae:.2f} \\n\")\n",
    "\n",
    "predict_depth(rf, test_data, depth = 1)\n",
    "predict_depth(rf, test_data, depth = 2)\n",
    "predict_depth(rf, test_data, depth = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data[FEATURES_MVP], train_data[\"value\"]\n",
    "X_test, y_test = test_data[FEATURES_MVP], test_data[\"value\"]\n",
    "\n",
    "for d in [1, 2,3, 4, 8, 12, 16]:\n",
    "    rf = RandomForestRegressor(max_features=\"sqrt\", n_estimators=1000, max_depth=d, bootstrap=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_hat = rf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    rmse = mean_squared_error(y_test, y_hat, squared=False)\n",
    "    mae = mean_absolute_error(y_test, y_hat)\n",
    "\n",
    "    print(f\"Tiefe {d}: RMSE {rmse}, MAE {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test - y_hat\n",
    "\n",
    "plt.hist(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train_data[FEATURES_MVP], train_data[\"value\"]\n",
    "X_test, y_test = test_data[FEATURES_MVP], test_data[\"value\"]\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "y_hat = rf.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, y_hat, squared=False)\n",
    "mae = mean_absolute_error(y_test, y_hat)\n",
    "\n",
    "print(mae, rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_data[\"value\"]\n",
    "\n",
    "rmse = mean_squared_error(y_test, test_data[FEATURE_NAIVE], squared=False)\n",
    "mae = mean_absolute_error( y_test, test_data[FEATURE_NAIVE])\n",
    "print(mae, rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtrees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
